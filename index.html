<!DOCTYPE html>
<!-- saved from url=(0028)https://yijiaweng.github.io/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Qitao Zhao</title>
  
  <meta name="author" content="Qitao Zhao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="QPaNZhsyKoL6cl0MvvWXNphUylKijfs8zZ715TRKwAs" />
  <meta name="baidu-site-verification" content="code-0Y3TTAZsxk" />
  <meta name="description" content="Qitao Zhao, undergrad student in Shandong University.">
  <meta name="keywords" content="Qitao Zhao, sdu, Shandong University, deep learning, machine learning">

  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?88afe9fed85f44c7282e05fac9854e46";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
  
  <link rel="stylesheet" type="text/css" href="./files/stylesheet.css">
  <link rel="icon" type="image/png" href="research/PoseFormerV2/figures/Thinking_Face.jpg">
</head>

<body data-new-gr-c-s-check-loaded="14.1101.0" data-gr-ext-installed="">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Qitao Zhao | ËµµÊ∑áÊ∂õ</name>
              </p>
              <p>
                I'm a Master's student in Computer Vision (<b>MSCV</b>) at Carnegie Mellon University. I am currently working on sparse-view 3D reconstruction in the wild, advised by Prof. <a href="https://shubhtuls.github.io/">Shubham Tulsiani</a>. 
                Prior to this, I had the privilege of working with Prof. <a href="https://www.crcv.ucf.edu/chenchen/">Chen Chen</a> as an undergraduate research intern at the University of Central Florida. I completed my undergraduate studies at Shandong University in June 2023. 
              </p>
              <p>
                <b>I am applying for a Ph.D. for Fall 2025.</b>
              </p>
              <p style="text-align:center">
                <a href="mailto:qitaoz@andrew.cmu.edu">Email</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=r9nmsasAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/QitaoZhao/">GitHub</a> &nbsp;/&nbsp;
                <a href="https://x.com/qitao_zhao">twitter</a> &nbsp;/&nbsp;
                <a href="https://qitaozhao.github.io/files/Qitao_CV.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="https://qitaozhao.github.io/images/qitaoz-3.jpg"><img style="width:60%;max-width:60%" alt="profile photo" src="https://qitaozhao.github.io/images/qitaoz-3.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research focuses on inferring 3D structures from <b>sparse</b> 2D signals, such as predicting a 3D human pose from a few 2D poses or estimating 3D shapes from sparse-view images. I am passionate about recovering visually and physically plausible 3D structures from everyday observations (e.g., photographs or video clips) or through our interactions with the world around us.
                <!-- My research focuses on inferring 3D structures from <b>sparse</b> 2D signals, such as predicting a 3D human pose from a few 2D poses or estimating 3D shapes from sparse-view images. -->
                <!-- My research interests mainly lie in 3D computer vision, especially inferring 3D from 2D spatial-temporal modeling. Potential research topics include human-centric shape/motion understanding and human-environment interaction modeling. I am also interested in revisiting well-established signal-processing techniques in the context of modern computer vision. -->
			          <!-- My research interests mainly lie in <strong>human shape/motion understanding</strong> and modeling advanced <strong>human-environment interactions</strong>.  -->
                <!-- I am also interested in revisiting well-established signal processing techniques in the context of learning-based computer vision, which I believe may bring new insights. -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src="./images/DiffusionSfM.gif" width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion</papertitle>
              <br>
              <strong>Qitao Zhao</strong>,
              <a href="https://amyxlase.github.io/">Amy Lin</a>,
              <a href="https://jefftan969.github.io/">Jeff Tan</a>,
              <a href="https://jasonyzhang.com/">Jason Y. Zhang</a>,
              <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>,
              <a href="https://shubhtuls.github.io/">Shubham Tulsiani</a>
              <br>
              IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025
              <br>
              <a href="https://qitaozhao.github.io/research/DiffusionSfM/DiffusionSfM.pdf">paper (Coming Soon)</a> /
              <a href="https://qitaozhao.github.io/DiffusionSfM">project page</a> /
              <a href="https://github.com/QitaoZhao/DiffusionSfM">code</a>
              <p></p>
            </td>
        </tr>

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src="./images/SparseAGS.gif" width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis</papertitle>
              <br>
              <strong>Qitao Zhao</strong>,
              <a href="https://shubhtuls.github.io/">Shubham Tulsiani</a>
              <br>
              38th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024
              <br>
              <a href="https://arxiv.org/abs/2412.03570">paper</a> /
              <a href="https://qitaozhao.github.io/SparseAGS">project page</a> /
              <a href="https://github.com/QitaoZhao/SparseAGS/tree/main">code</a> /
              <a href="https://x.com/shubhtuls/status/1866176971182657941">twitter thread</a>
              <p></p>
            </td>
        </tr>

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src="./images/context-aware poseformer.png" width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation</papertitle>
              <br>
              <strong>Qitao Zhao</strong>,
              <a href="https://zczcwh.github.io/">Ce Zheng</a>,
              <a href="https://humanperception.github.io/">Mengyuan Liu</a>,
              <a href="https://www.crcv.ucf.edu/chenchen/">Chen Chen</a>
              <br>
              37th Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2023
              <br>
              <a href="https://arxiv.org/abs/2311.03312">paper</a> /
              <a href="https://qitaozhao.github.io/ContextAware-PoseFormer">project page</a> /
              <a href="https://github.com/QitaoZhao/ContextAware-PoseFormer">code</a> /
              <a href="https://neurips.cc/virtual/2023/poster/70586">video</a>
              <p></p>
            </td>
        </tr>

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src="./images/PoseFormerV2.png" width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>PoseFormerV2: Exploring Frequency Domain for Efficient and Robust 3D Human Pose Estimation</papertitle>
              <br>
              <strong>Qitao Zhao</strong>,
              <a href="https://zczcwh.github.io/">Ce Zheng</a>,
              <a href="https://humanperception.github.io/">Mengyuan Liu</a>,
              <a href="https://wangpichao.github.io/">Pichao Wang</a>,
              <a href="https://www.crcv.ucf.edu/chenchen/">Chen Chen</a>
              <br>
              IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023
              <br>
              <a href="https://arxiv.org/abs/2303.17472">paper</a> /
              <a href="https://qitaozhao.github.io/PoseFormerV2">project page</a> / 
              <a href="https://github.com/QitaoZhao/PoseFormerV2">code</a> /
              <a href="https://www.youtube.com/watch?v=2xVNrGpGldM">video</a>
              <p></p>
            </td>
         </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td style="padding-left:15px;padding-right:10px;width:20%;vertical-align:middle"><img src="./images/cmu.png" ,="" width="85%"></td>
            <td width="80%" valign="center">
              <b>Carnegie Mellon University</b>, Pittsburgh, PA, USA
              <br> 2023.08 - 2024.12 (expected) 
              <br> Master of Science in Computer Vision (<b>MSCV</b>)
              <br> GPA: 4.11/4.3
            </td>
          </tr>
          <tr>
            <td style="padding-left:10px;padding-right:10px;width:20%;vertical-align:middle"><img src="./images/shandong_uni.jpeg" ,="" width="90%"></td>
            <td width="80%" valign="center">
              <b>Shandong University</b>, Qingdao, Shandong, China
              <br> 2019.09 - 2023.06
              <br> Bachelor of Engineering, Electronic Science and Technology
              <br> GPA: 94.61/100, rank 2/21
              <br>
              <br> <b>Outstanding Thesis Award</b> (Ranked 1st out of 7 finalists among 350+ students in the department)
              <br> <b>National Scholarship 2020</b> (Awarded to the top 0.2% of students nationwide)
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="./images/cmu.png" ,="" width="90%"></td>
            <td width="80%" valign="center">
              <b>Carnegie Mellon University</b>, Physical Perception Lab 
              <br> 2023.09 - Present
              <br>
              <br> Graduate researcher on <b>sparse-view reconstruction in the wild</b>
              <br> Advisor: Prof. <a href="https://shubhtuls.github.io/">Shubham Tulsiani</a>
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="./images/ucf.png" ,="" width="90%"></td>
            <td width="80%" valign="center">
              <b>University of Central Florida</b>, CRCV
              <br> 2022.04 - 2023.08
              <br>
              <br> Undergrad research intern on <b>3D human pose estimation</b>
              <br> Advisor: Prof. <a href="https://www.crcv.ucf.edu/chenchen/">Chen Chen</a>
            </td>
          </tr>
          <!-- <tr>
            <td style="padding-left:10px;padding-right:10px;width:20%;vertical-align:middle"><img src="./images/shandong_uni.jpeg" ,="" width="90%"></td>
            <td width="80%" valign="center">
              <b>Shandong University</b>, Qingdao, Shandong, China
              <br> 2021.09 - 2022.04
              <br>
              <br> Research Intern on <b>cross-view gait recognition</b>
              <br> Advisor: Prof. <a href="https://dblp.org/pid/96/10791.html">Xianye Ben</a>
            </td>
          </tr> -->

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Miscellaneous</heading>
              <p>
                I enjoy playing basketball üèÄ with friends, and my idol is Kobe Bryant. Kobe impressed me with his diligence, concentration and high standard. He influenced every aspect of my life. R.I.P.
                <!-- <br> Away from computers, I enjoy learning foreign languages, watching musicalsüé≠üé∂, and cookingüç≥. -->
              </p>

              <a href="https://www.easycounter.com/">
              <img src="https://www.easycounter.com/counter.php?qitaozhao" ,="" width="10%"
              border="0" alt="Web Site Hit Counter"></a><a href="https://www.easycounter.com/">    unique visitors since Nov 2022</a>
            </td>
          </tr>
        </tbody></table>

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template stolen from <a href="https://yijiaweng.github.io">Yijia Weng</a> (and also <a href="https://jonbarron.info/">Jon Barron</a>). 
              <br> Last updated: Dec 16, 2024 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </tbody></table>

</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>